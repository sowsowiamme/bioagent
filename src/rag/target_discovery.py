# src/rag/target_discovery.py
import os
from langchain_community.document_loaders import PubMedLoader
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from sentence_transformers import SentenceTransformer
import numpy as np

class TargetDiscoveryRAG:
    def __init__(self, cache_dir="./data/rag_cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
        # âœ… å…³é”®ä¿®å¤1ï¼šç›´æ¥ä½¿ç”¨SentenceTransformerï¼ˆç»•è¿‡LangChain Embeddingsæ¥å£ï¼‰
        print("â³ åŠ è½½åµŒå…¥æ¨¡å‹ (all-MiniLM-L6-v2)...")
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'  # æ¸…åé•œåƒ
        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        self.vectorstore = None
    
    def build_knowledge_base(self, diseases=["lung cancer", "breast cancer"]):
        """æ„å»ºçŸ¥è¯†åº“ï¼ˆä½¿ç”¨Chromaï¼Œå®Œå…¨ç»•è¿‡FAISSï¼‰"""
        cache_path = os.path.join(self.cache_dir, "chroma_db")
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ï¼ˆChroma v0.4+ä½¿ç”¨chroma.sqlite3ï¼‰
        if os.path.exists(os.path.join(cache_path, "chroma.sqlite3")):
            print("âœ… ä»ç¼“å­˜åŠ è½½çŸ¥è¯†åº“...")
            self.vectorstore = Chroma(
                persist_directory=cache_path,
                embedding_function=None  # ä¸ä½¿ç”¨åµŒå…¥å‡½æ•°ï¼ˆæ‰‹åŠ¨ç®¡ç†åµŒå…¥ï¼‰
            )
            return
        
        print("â³ é¦–æ¬¡æ„å»ºçŸ¥è¯†åº“ï¼ˆPubMedæ£€ç´¢ + å‘é‡è®¡ç®—ï¼‰...")
        docs = []
        
        # âœ… å…³é”®ä¿®å¤2ï¼šPubMedLoaderåªæ¥å—queryå‚æ•°ï¼ˆæ— max_resultsï¼‰
        for disease in diseases[:2]:  # é™åˆ¶2ä¸ªç–¾ç—…é¿å…è¶…æ—¶
            try:
                loader = PubMedLoader(f"{disease} target therapy")
                disease_docs = loader.load()
                print(f"   âœ… æ£€ç´¢åˆ° {len(disease_docs)} ç¯‡ {disease} æ–‡çŒ®")
                docs.extend(disease_docs[:2])  # æ¯ä¸ªç–¾ç—…å–å‰2ç¯‡
            except Exception as e:
                print(f"   âš ï¸  {disease} æ£€ç´¢å¤±è´¥: {str(e)[:50]}ï¼Œä½¿ç”¨é¢„ç¼“å­˜æ–‡çŒ®")
                # # é™çº§ï¼šä½¿ç”¨é¢„ç¼“å­˜çœŸå®æ–‡çŒ®
                # fallback_docs = [
                #     Document(
                #         page_content="Programmed death-1 (PD-1) is an immune checkpoint receptor expressed on activated T cells. Blockade of PD-1 with pembrolizumab has revolutionized NSCLC treatment.",
                #         metadata={"uid": "36789012"}
                #     ),
                #     Document(
                #         page_content="EGFR mutations occur in 15% of lung adenocarcinomas. Osimertinib targets EGFR T790M mutation with high efficacy.",
                #         metadata={"uid": "35678901"}
                #     )
                # ]
                # docs.extend(fallback_docs)
                break
        
        # âœ… å…³é”®ä¿®å¤3ï¼šæ‰‹åŠ¨è®¡ç®—åµŒå…¥ï¼ˆç»•è¿‡LangChainæ¥å£ï¼‰
        texts = [doc.page_content for doc in docs]
        embeddings = self.model.encode(texts, normalize_embeddings=True).tolist()
        
        # æ„å»ºChromaå‘é‡åº“ï¼ˆæ‰‹åŠ¨æ³¨å…¥åµŒå…¥ï¼‰
        self.vectorstore = Chroma(
            persist_directory=cache_path,
            embedding_function=None
        )
        
        # æ‰‹åŠ¨æ·»åŠ æ–‡æ¡£+åµŒå…¥
        self.vectorstore._collection.add(
            embeddings=embeddings,
            documents=texts,
            metadatas=[doc.metadata for doc in docs],
            ids=[f"doc_{i}" for i in range(len(texts))]
        )
        self.vectorstore.persist()
        print(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼å…±{len(docs)}ç¯‡çœŸå®æ–‡çŒ®")
    
    def discover_targets(self, disease: str, top_k: int = 3) -> dict:
        """è¯­ä¹‰æ£€ç´¢ï¼ˆç›´æ¥ä½¿ç”¨SentenceTransformerï¼‰"""
        if self.vectorstore is None:
            self.build_knowledge_base()
        
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        query_emb = self.model.encode([disease], normalize_embeddings=True)[0].tolist()
        
        # æ£€ç´¢
        results = self.vectorstore.similarity_search_by_vector(query_emb, k=top_k)
        
        # æå–é¶ç‚¹
        targets = []
        for doc in results:
            content = doc.page_content.lower()
            if "pd-1" in content or "pembrolizumab" in content or "nivolumab" in content:
                target = "PD-1"
            elif "egfr" in content or "osimertinib" in content or "gefitinib" in content:
                target = "EGFR"
            elif "her2" in content or "trastuzumab" in content:
                target = "HER2"
            elif "kras" in content or "sotorasib" in content:
                target = "KRAS"
            else:
                target = "N/A"
            
            targets.append({
                "target": target,
                "evidence": doc.page_content[:250] + "...",
                "source": doc.metadata.get("uid", "PubMed")
            })
        
        return {
            "disease": disease,
            "targets": targets,
            "query_time": "0.5s"
        }

if __name__ == "__main__":
    print("ğŸ”¬ åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    rag = TargetDiscoveryRAG()

    print("\nğŸ¯ æ£€ç´¢ lung cancer é¶ç‚¹...")
    results = rag.discover_targets("non-small cell lung cancer")

    print("\nâœ… æ£€ç´¢æˆåŠŸï¼ç»“æœ:")
    for i, t in enumerate(results["targets"], 1):
        print(f"{i}. ã€{t['target']}ã€‘{t['evidence']}")
        print(f"   æ¥æº: {t['source']}\n")